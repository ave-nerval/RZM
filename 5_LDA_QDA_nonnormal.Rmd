---
title: "DN5: LDA vs QDA vs logistična regresija v primeru nenormalnih porazdelitev - uporaba kopul"
author: "Eva Lavrenčič"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F)

load("poprava_dn5_wrks.RData")
library(MASS)
library(ggplot2)
library(psych)
library(see)
library(effectsize)
library(kableExtra)
```


# UVOD

Namen naloge je bil primerjati linearno diskriminantno analizo (LDA), kvadratno diskriminantno analizo (QDA) in logistično regresijo na ne-(večrazsežno)normalnih porazdelitvah, pri čemer smo podatke generirali z uporabo kopul. Opazovali smo vpliv porazdelitve, razlike med povprečji skupin in korelacije med spremenljivkami na delež pravilno razvrščenih enot pri posamezni metodi.



# ZASNOVA SIMULACIJE

Podatke za 2 skupini smo generirali iz treh multivariatnih ne-normalnih porazdelitev s pomočjo normalnih kopul. Število spremenljivk smo nastavili na tri, skupini sta bili enako veliki (n=30). Uporabili smo tri robne porazdelitve: beta, eksponentna in F porazdelitev. Pri posameznem generiranju podatkov so bile robne porazdelitve vseh spremenljivk enake. Korelacije med pari spremenljivk v prvi skupini so bile 0.2, korelacije med pari spremenljivk v drugi skupini pa smo spreminjali (0.2, 0.4, 0.6, 0.8).

Vrednosti spremenljivk smo centrirali, tako da so bile v prvi skupini pričakovane vrednosti vseh spremenljivk enake 0, v drugi skupini pa smo pričakovano vrednost spremenljivk spreminjali (0, 0.2, 0.4, 0.6, 0.8 ali 1.0). Po centralizaciji smo vrednosti spremenljivk standardizirali tako, da smo jih delili s teoretičnim standardnim odklonom.

Spreminjali smo torej 3 parametre:

- korelacija med spremenljivkami v drugi skupini: 0.2, 0.4, 0.6, 0.8 (korelacija med vsemi spremenljivkami je bila enaka)

- porazdelitev vrednosti spremenljivk: beta, eksponentna, F porazdelitev; porazdelitve se razlikujejo po obliki (Slika 1) in varianci (Tabela 1); povprečja centriramo, vrednosti delimo s standardnim odklonom porazdelitve

- razlika med povprečji spremenljivk po skupinah: 0, 0.2, 0.4, 0.6, 0.8, 1.0


Zanima nas, kolikšen delež enot pravilno razvrstimo v skupine glede na izbrane parametre in metodo razvrščanja. V primerih, ko je korelacija med pari spremenljivk v drugi skupini različna od 0.2, je kršena predpostavka linearne diskriminantne analize o enakosti variančno-kovariančnih matrik v populacijskih skupinah. QDA in logistična regresija nimata predpostavke o enakosti variančno-kovariančnih matrik. LDA in QDA imata tudi predpostavko o multivariatni normalni porazdelitvi vrednosti spremenljivk.


Delež pravilno ocenjenih enot ocenimo na novih testnih podatkih (n=500) iz iste populacije. Izvedli smo po 500 ponovitev simulacij za vsako kombinacijo preučevanih parametrov.



```{r fig.cap="Gostote izbranih porazdelitev."}
curve(dbeta(x, 6, 2), from=0, to = 5, ylab="Gostota porazdelitve")
curve(dexp(x, 1), from=0, to = 5, col="red", add=T)
curve(df(x, 30, 30), from=0, to = 5, add=T, col="green")

legend(3, 2.9, legend=c("beta, a=6, b=2", "F, df1=30, df2=30", "exp, rate = 1"),
       col=c("black", "green", "red"), lty=1, cex=0.8, title="Parametri porazdelitve")

```


```{r}
Porazdelitev <- c("beta", "F", "exp")
Parametri <- c("a=6, b=2", "df1=30, df2=30", "rate = 1")
Alpha <- 6
Beta <- 2
df2 <- 30
df1 <- 30
Std_odklon <- c(round(sqrt((Alpha*Beta)/((Alpha+Beta)^2*(Alpha+Beta+1))),3), round(sqrt((2*df2^2*(df1+df2-2))/(df1*(df2-2)^2*(df2-4))),3), 1.0)

beta_std <- sqrt((Alpha*Beta)/((Alpha+Beta)^2*(Alpha+Beta+1)))
F_std <- sqrt((2*df2^2*(df1+df2-2))/(df1*(df2-2)^2*(df2-4)))
exp_std <- 1


Tabela1 <- cbind(Porazdelitev, Parametri, Std_odklon)

rownames(Tabela1) = c("1", "2", "3")
colnames(Tabela1) <- c("Porazdelitev", "Parametri", "Standarni odklon")
kable(Tabela1,caption = "Tabela 1: Uporabljene porazdelitve") %>%
  kable_styling("striped",full_width = F, font_size=10)

```


```{r}
betaCopula <- function(Sigma, n, shape1, shape2){
  X <- mvrnorm(n = n, mu = rep(0, 3), Sigma = Sigma)
  Xuni <- pnorm(q = X)
  Xbeta <- Xuni
  Xbeta[,1] <- qbeta(p = Xuni[,1], shape1 = shape1, shape2 = shape2)
  Xbeta[,2] <- qbeta(p = Xuni[,2], shape1 = shape1, shape2 = shape2)
  Xbeta[,3] <- qbeta(p = Xuni[,3], shape1 = shape1, shape2 = shape2)
  
  return(Xbeta)
}


expCopula <- function(Sigma, n, rate){
  X <- mvrnorm(n = n, mu = rep(0, 3), Sigma = Sigma)
  Xuni <- pnorm(q = X)
  Xexp <- Xuni
  Xexp[,1] <- qexp(p = Xuni[,1], rate = rate)
  Xexp[,2] <- qexp(p = Xuni[,2], rate = rate)
  Xexp[,3] <- qexp(p = Xuni[,3], rate = rate)
  
  return(Xexp)
}

FCopula <- function(Sigma, n, df1, df2){
  X <- mvrnorm(n = n, mu = rep(0, 3), Sigma = Sigma)
  Xuni <- pnorm(q = X)
  XF <- Xuni
  XF[,1] <- qf(p = Xuni[,1], df1 = df1, df2 = df2)
  XF[,2] <- qf(p = Xuni[,2], df1 = df1, df2 = df2)
  XF[,3] <- qf(p = Xuni[,3], df1 = df1, df2 = df2)
  
  return(XF)
}


```


```{r}
panel.hist <- function(x, ...)
{
    usr <- par("usr"); on.exit(par(usr))
    par(usr = c(usr[1:2], 0, 1.5) )
    h <- hist(x, plot = FALSE)
    breaks <- h$breaks; nB <- length(breaks)
    y <- h$counts; y <- y/max(y)
    rect(breaks[-nB], 0, breaks[-1], y)
}

Sigma1 <- matrix(0.2,nrow=3, ncol=3)
diag(Sigma1) <- 1
n <- 60
beta_mu <- shape1/(shape1+shape2)
beta_std <- sqrt((shape1*shape2)/((shape1+shape2)^2*(shape1+shape2+1)))



set.seed(65768)
beta <- betaCopula(Sigma1, n=60, 6, 2)
beta <- as.data.frame(beta - beta_mu)
beta <- beta/beta_std
beta$skupina <- c(rep(1,30), rep(2,30))


my_cols <- c("#00AFBB", "#E7B800")  
```


```{r fig.cap="Primer za beta porazdelitev, povprečja in korelacije spremenljivk so enake po skupinah"}
pairs(beta[,1:3], pch = 19,  cex = 1,
      col = my_cols[beta$skupina],
      lower.panel=NULL, diag.panel = panel.hist)

```








```{r}
df1 <- df2 <- 30
shape1 <- 6
shape2 <- 2
#standardni odkloni
beta_std <- sqrt((shape1*shape2)/((shape1+shape2)^2*(shape1+shape2+1)))
F_std <- sqrt((2*df2^2*(df1+df2-2))/(df1*(df2-2)^2*(df2-4)))
exp_std <- 1
#povprecja
exp_mu <- 1
F_mu <- df2/(df2-2)
beta_mu <- shape1/(shape1+shape2)


Sigma1 <- matrix(0.2,nrow=3, ncol=3)
diag(Sigma1) <- 1

Sigma2 <- matrix(0.6,nrow=3, ncol=3)
diag(Sigma2) <- 1

n <- 30

set.seed(65768)
beta1 <- betaCopula(Sigma1, n, 6, 2)
beta1 <- beta1-beta_mu

beta2 <- betaCopula(Sigma2, n, 6, 2)
beta2 <- beta2-beta_mu + 0.4

beta <- as.data.frame(rbind(beta1, beta2))
beta <- beta/beta_std
beta$skupina <- c(rep(1,30), rep(2,30))

exp1 <- expCopula(Sigma1, n, 1)
exp1 <- exp1-exp_mu

exp2 <- expCopula(Sigma2, n, 1)
exp2 <- exp2-exp_mu + 0.4

exp <- as.data.frame(rbind(exp1, exp2))
exp <- exp/exp_std
exp$skupina <- c(rep(1,30), rep(2,30))

Fspr1 <- FCopula(Sigma1, n, 30, 30)
Fspr1 <- Fspr1-F_mu

Fspr2 <- FCopula(Sigma2, n, 30, 30)
Fspr2 <- Fspr2-F_mu + 0.4


Fspr <- as.data.frame(rbind(Fspr1, Fspr2))
Fspr <- Fspr/F_std
Fspr$skupina <- c(rep(1,30), rep(2,30))


my_cols <- c("#00AFBB", "#E7B800")  

```

```{r fig.cap="Primer za beta porazdelitev, povprečja v 2. skupini = 0.4, korelacija v 2. skupini = 0.6; skupini sta skoraj povsem ločeni"}
pairs(beta[,1:3], pch = 19,  cex = 1,
      col = my_cols[beta$skupina],
      lower.panel=NULL, diag.panel = panel.hist)
```

```{r fig.cap="Primer za eksponentno porazdelitev, povprečja v 2. skupini = 0.4, korelacija v 2. skupini = 0.6; skupini sta slabo ločeni (večja varianca vrednosti spremenljivk)"}
pairs(exp[,1:3], pch = 19,  cex = 1,
      col = my_cols[exp$skupina],
      lower.panel=NULL, diag.panel = panel.hist)
```



\newpage
\newpage


# REZULTATI SIMULACIJE

```{r fig.cap="Delez pravilno razvrscenih enot glede na porazdelitev, razliko med povprečji, korelacijo med spremenljivkami v 2. skupini in metodo (LDA, QDA oz. LOG regresija)"}
ggplot(data = MeltedData, mapping = aes(x = razlika_povpr, y = value, group=variable, col=variable)) +
  facet_grid(kor_2 ~ porazdelitev, labeller = label_both) +
  stat_summary(fun = mean, geom="line")  +
  ylab("Delez pravilno razvrscenih enot")

```


Delež pravilno razvrščenih enot se z večanjem razlike med povprečji spremenljivk po skupinah pri vseh metodah povečuje, saj so si pri večjih razlikah enote bolj narazen. Pri beta porazdelitvi že pri razliki povprečij 0.4 opazimo zelo dobro ločbo (skupine so skoraj popolnoma ločene; pri beta porazdelitvi, ki je definirana in intervalu [0,1], so vrednosti znotraj posamezne skupine relativno blizu skupaj, zato že manjši premik povprečja spremenljivk skupini dobro loči). Nekoliko slabša ločba je pri enakih razlikah med povprečju v primeru F porazdelitve. Najslabše so ločene skupine iz eksponentne porazdelitve, ki je močno asimetrična v desno, generirane vrednosti pred standardizacijo so bolj razpršene kot pri beta ali F porazdelitvi.



V primeru, ko je korelacija med spremenljivkami enaka za skupino 1 in 2, sta LDA in logistična regresija nekoliko boljši od QDA. Večja kot je korelacija med spremenljivkami v drugi skupini (kršena predpostavka LDA), boljša je QDA v primerjavi z drugima dvema metodama, vendar se razlika s povečevanjem razlike med povrečji zmanjšuje. Pri višjih korelacijah med spremenljivkami v drugi skupini metoda QDA enote razvrsti bolje kot po naključju, tudi ko je razlika med povprečji enaka 0 (pri QDA dovolimo nelinearne meje skupin in tako uspemo zajeti manjše prekrivanje skupin zaradi korelacije med spremenljivkami). LDA in logistična regresija pravilno razvrstita približno enak delež enot pri vseh kombinacijah parametrov.


```{r fig.cap="Učinki dejavnikov in interakcij na delež pravilno razvrščenih enot z metodo LDA"}
plot(eta_squared(modelLDA))

```

```{r fig.cap="Učinki dejavnikov in interakcij na delež pravilno razvrščenih enot z metodo QDA"}
plot(eta_squared(modelQDA))

```



```{r fig.cap="Učinki dejavnikov in interakcij na delež pravilno razvrščenih enot z logistično regresijo"}

plot(eta_squared(modelLR))


```


```{r fig.cap="Učinki dejavnikov in interakcij na razliko v deležu pravilno razvrščenih enot med LDA in QDA"}

plot(eta_squared(modelRazlika))

```

Največji učinek na delež pravilno razvrščenih enot ima razlika med povprečji; velik učinek imata tudi porazdelitev spremenljivk ter interakcija med razliko povprečij ter porazdelitvijo. Na razliko med uspešnostjo razvrščanja med LDA oz. LR ter QDA najbolj vpliva korelacija med spremenljivkami v drugi skupini.



# ZAKLJUČEK

Pri spreminjanju preučevanih parametrov nismo opazili razlik v deležu pravilno razvrščenih enot med LDA in logistično regresijo; LDA in QDA dobro razvrščata enote tudi pri odstopanju od multivariatne normalnosti. Po pričakovanju se je uspešnost razvrščanja večala s povečevanjem razlike med povprečji spremenljivk glede na skupino. Ko so razlike v korelaciji med spremenljivkami po skupinah velike, je smiselno uporabiti QDA.


